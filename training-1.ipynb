{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora,models,similarities\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('squad_train_doc.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passages</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'context': 'Architecturally, the school has ...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'context': 'Beyoncé Giselle Knowles-Carter (...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'context': 'Montana i/mɒnˈtænə/ is a state i...</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'context': 'The phrase \"in whole or in part\"...</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'context': 'The emergence of resistance of b...</td>\n",
       "      <td>Antibiotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            passages                     title\n",
       "0  [{'context': 'Architecturally, the school has ...  University_of_Notre_Dame\n",
       "1  [{'context': 'Beyoncé Giselle Knowles-Carter (...                   Beyoncé\n",
       "2  [{'context': 'Montana i/mɒnˈtænə/ is a state i...                   Montana\n",
       "3  [{'context': 'The phrase \"in whole or in part\"...                  Genocide\n",
       "4  [{'context': 'The emergence of resistance of b...               Antibiotics"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "question_list = []\n",
    "for i in range(len(data)):\n",
    "    context_temp = []\n",
    "    question_temp = []\n",
    "    for j in range(len(data['passages'][i])):\n",
    "        context_temp.append(data['passages'][i][j]['context'])\n",
    "        question_temp.append(data['passages'][i][j]['questions'])\n",
    "    context_list.append(context_temp)\n",
    "    question_list.append(question_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'context':context_list,'questions':question_list,'title':data.title}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data = dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[To whom did the Virgin Mary allegedly appear...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...</td>\n",
       "      <td>[[When did Beyoncé release her first solo albu...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Montana i/mɒnˈtænə/ is a state in the Western...</td>\n",
       "      <td>[[How many ranges are part of the Rocky Mounta...</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The phrase \"in whole or in part\" has been sub...</td>\n",
       "      <td>[[Which phrase is especially contentious withi...</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The emergence of resistance of bacteria to an...</td>\n",
       "      <td>[[What is resistance to antibiotics a cause of...</td>\n",
       "      <td>Antibiotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...   \n",
       "2  [Montana i/mɒnˈtænə/ is a state in the Western...   \n",
       "3  [The phrase \"in whole or in part\" has been sub...   \n",
       "4  [The emergence of resistance of bacteria to an...   \n",
       "\n",
       "                                           questions                     title  \n",
       "0  [[To whom did the Virgin Mary allegedly appear...  University_of_Notre_Dame  \n",
       "1  [[When did Beyoncé release her first solo albu...                   Beyoncé  \n",
       "2  [[How many ranges are part of the Rocky Mounta...                   Montana  \n",
       "3  [[Which phrase is especially contentious withi...                  Genocide  \n",
       "4  [[What is resistance to antibiotics a cause of...               Antibiotics  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_listperdoc = [' '.join(context) for context in new_df.context]\n",
    "question_listperdoc =  [' '.join(question) for questions in new_df.questions for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_listperdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question_listperdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_question_context =[]\n",
    "untokenized_question_context = []\n",
    "for question,context in zip(question_listperdoc,context_listperdoc):\n",
    "    question_words = [word for word in nltk.word_tokenize(question) if word not in stop_words]\n",
    "    context_words = [word for word in nltk.word_tokenize(context) if word not in stop_words]\n",
    "    \n",
    "    tokenized_question_context.append(question_words+context_words)\n",
    "    untokenized_question_context.append(' '.join(question_words+context_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25_model = gensim.summarization.bm25.BM25(tokenized_question_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(query):\n",
    "    scores = BM25_model.get_scores(query.split(),1)\n",
    "    bm25_df = pd.DataFrame(data={'title':new_df.title,'bm25_score':scores}).sort_values(by=['bm25_score'],ascending=False)\n",
    "    bm25_df['bm25_rank'] = [i for i in range(1, len(bm25_df.title)+1)]\n",
    "    return bm25_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>13.112193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Prime_minister</td>\n",
       "      <td>10.379726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hanover</td>\n",
       "      <td>6.471414</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Genome</td>\n",
       "      <td>4.326248</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iranian_languages</td>\n",
       "      <td>4.301328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comprehensive_school</td>\n",
       "      <td>4.266961</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Architecture</td>\n",
       "      <td>4.154598</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Sony_Music_Entertainment</td>\n",
       "      <td>4.154463</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Human_Development_Index</td>\n",
       "      <td>4.146440</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Saint_Barth%C3%A9lemy</td>\n",
       "      <td>4.003093</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  bm25_score  bm25_rank\n",
       "0    University_of_Notre_Dame   13.112193          1\n",
       "28             Prime_minister   10.379726          2\n",
       "132                   Hanover    6.471414          3\n",
       "25                     Genome    4.326248          4\n",
       "35          Iranian_languages    4.301328          5\n",
       "26       Comprehensive_school    4.266961          6\n",
       "38               Architecture    4.154598          7\n",
       "50   Sony_Music_Entertainment    4.154463          8\n",
       "39    Human_Development_Index    4.146440          9\n",
       "24      Saint_Barth%C3%A9lemy    4.003093         10"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25('What is Grotto at Notre Dame?').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "tfidf_dict = corpora.Dictionary(tokenized_question_context)\n",
    "#tfidf_dict.save('./tmp/squad.dict') \n",
    "raw_corpus = [tfidf_dict.doc2bow(doc) for doc in tokenized_question_context]\n",
    "corpora.MmCorpus.serialize('./tmp/squad.mm', raw_corpus)\n",
    "corpus = corpora.MmCorpus('./tmp/squad.mm')\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "tfidf_model = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "#tfidf_model.save('./tmp/squad.TFIDF_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(query):\n",
    "    query_1 = []\n",
    "    query_1.append(nltk.word_tokenize(query))\n",
    "    query_raw_corpus = [tfidf_dict.doc2bow(i) for i in query_1]\n",
    "    corpora.MmCorpus.serialize('./tmp/query.mm',query_raw_corpus)\n",
    "    query_corpus = corpora.MmCorpus('./tmp/query.mm')\n",
    "    similarity_table = tfidf_model[query_corpus]\n",
    "    ranks = scipy.stats.rankdata(similarity_table, method = 'max')\n",
    "    similarity_table = list(np.array(similarity_table).flatten())\n",
    "    tfidf_df = pd.DataFrame({'title':new_df.title, 'tfidf_score':similarity_table}).sort_values(by=['tfidf_score'],ascending=False)\n",
    "    tfidf_df['tfidf_rank'] = [i for i in range(1, len(new_df.title)+1)]\n",
    "    return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>tfidf_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0.407653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Southern_Europe</td>\n",
       "      <td>0.081975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Prime_minister</td>\n",
       "      <td>0.053481</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Architecture</td>\n",
       "      <td>0.053332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comprehensive_school</td>\n",
       "      <td>0.047113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Hunter-gatherer</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dutch_Republic</td>\n",
       "      <td>0.041179</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Human_Development_Index</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Iranian_languages</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Symbiosis</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  tfidf_score  tfidf_rank\n",
       "0   University_of_Notre_Dame     0.407653           1\n",
       "40           Southern_Europe     0.081975           2\n",
       "28            Prime_minister     0.053481           3\n",
       "38              Architecture     0.053332           4\n",
       "26      Comprehensive_school     0.047113           5\n",
       "52           Hunter-gatherer     0.041910           6\n",
       "31            Dutch_Republic     0.041179           7\n",
       "39   Human_Development_Index     0.036986           8\n",
       "35         Iranian_languages     0.036660           9\n",
       "32                 Symbiosis     0.036566          10"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('What is Grotto at Notre Dame?').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceLabeled = []\n",
    "for sentenceID, sentence in enumerate(untokenized_question_context):\n",
    "    sentenceL = TaggedDocument(words=sentence.split(), tags = ['SENT_%s' %sentenceID])\n",
    "    sentenceLabeled.append(sentenceL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(vector_size=300, window=10, min_count=0, workers=11, alpha=0.005, min_alpha=0.025)\n",
    "doc2vec_model.build_vocab(sentenceLabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(50):\n",
    "#     print(epoch ,\"is running\")\n",
    "#     doc2vec_model.train(sentenceLabeled,total_examples=len(data),epochs=15000)\n",
    "#     doc2vec_model.alpha -= 0.0002  # decrease the learning rate\n",
    "#     doc2vec_model.min_alpha = doc2vec_model.alpha  # fix the learning rate, no decay\n",
    "#     doc2vec_model.save(\"doc2vec-withoutTime-15000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec_model = Doc2Vec.load(\"doc2vec-withoutTime-15000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(query):\n",
    "    similarity_score_matrix , list_doc_names, list_doc_scores, list_doc_ranks, rank = [], [], [], [], 1\n",
    "    avg_sentence = np.zeros((300))\n",
    "    count = 0\n",
    "    for word in nltk.word_tokenize(query):\n",
    "        if word in doc2vec_model.wv.vocab:\n",
    "            avg_sentence += doc2vec_model[word]\n",
    "            count += 1\n",
    "    if count !=0:\n",
    "        avg_sentence = avg_sentence/count\n",
    "    similarity_score_matrix.append(doc2vec_model.docvecs.most_similar([avg_sentence],topn=len(new_df.title)))\n",
    "    for each_compared_row in similarity_score_matrix[0]:\n",
    "        list_doc_names.append(each_compared_row[0])\n",
    "        list_doc_scores.append(each_compared_row[1])\n",
    "        list_doc_ranks.append(rank)\n",
    "        rank += 1\n",
    "    doc2vec_df = pd.DataFrame({'title':new_df.title, 'doc2vec_score':list_doc_scores, 'doc2vec_rank':list_doc_ranks})\n",
    "    return doc2vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doc2vec_score</th>\n",
       "      <th>doc2vec_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>0.168956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>0.164374</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montana</td>\n",
       "      <td>0.153053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genocide</td>\n",
       "      <td>0.138571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antibiotics</td>\n",
       "      <td>0.129852</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frédéric_Chopin</td>\n",
       "      <td>0.121766</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sino-Tibetan_relations_during_the_Ming_dynasty</td>\n",
       "      <td>0.120051</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IPod</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The_Legend_of_Zelda:_Twilight_Princess</td>\n",
       "      <td>0.114344</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spectre_(2015_film)</td>\n",
       "      <td>0.113487</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  doc2vec_score  doc2vec_rank\n",
       "0                        University_of_Notre_Dame       0.168956             1\n",
       "1                                         Beyoncé       0.164374             2\n",
       "2                                         Montana       0.153053             3\n",
       "3                                        Genocide       0.138571             4\n",
       "4                                     Antibiotics       0.129852             5\n",
       "5                                 Frédéric_Chopin       0.121766             6\n",
       "6  Sino-Tibetan_relations_during_the_Ming_dynasty       0.120051             7\n",
       "7                                            IPod       0.118357             8\n",
       "8          The_Legend_of_Zelda:_Twilight_Princess       0.114344             9\n",
       "9                             Spectre_(2015_film)       0.113487            10"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec('What is Grotto at Notre Dame?').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list =[]\n",
    "for i in range(len(new_df)):\n",
    "    question_list.append([question for questions in new_df.questions[i] for question in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_names_Sorted = list(new_df.title).copy()\n",
    "title_names_Sorted.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = [new_df.title[i] for i in range(new_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "doc_number = 0\n",
    "\n",
    "for all_questions_each_doc in question_list:\n",
    "    \n",
    "    one_hot_keys = []\n",
    "    for each_doc in title_names_Sorted:\n",
    "        if each_doc == title_list[doc_number]:\n",
    "            one_hot_keys.append(1)\n",
    "        else:\n",
    "            one_hot_keys.append(0)\n",
    "\n",
    "    for each_question in all_questions_each_doc:\n",
    "        BM_25_Dataframe = bm25(each_question).sort_values(by=['title'],ascending=True)\n",
    "        TFDIF_Dataframe = tfidf(each_question).sort_values(by=['title'],ascending=True)\n",
    "        Doc2Vec_Dataframe = doc2vec(each_question).sort_values(by=['title'],ascending=True)\n",
    "        \n",
    "        #WMD\n",
    "        #WMD_Dataframe = WMD(each_question).sort_values(by=['Document'],ascending=True)\n",
    "        #each_question_score_all_docs = pd.merge(pd.merge(pd.merge(BM_25_Dataframe, TFDIF_Dataframe), Doc2Vec_Dataframe), WMD_Dataframe)\n",
    "        \n",
    "        each_question_score_all_docs = pd.merge(pd.merge(BM_25_Dataframe, TFDIF_Dataframe), Doc2Vec_Dataframe)\n",
    "        list_each_question = [each_question for i in range(442)] \n",
    "        each_question_score_all_docs['question'] = list_each_question\n",
    "        each_question_score_all_docs['Actual_Document'] = one_hot_keys\n",
    "        frames.append(each_question_score_all_docs)\n",
    "        \n",
    "    doc_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>tfidf_rank</th>\n",
       "      <th>doc2vec_score</th>\n",
       "      <th>doc2vec_rank</th>\n",
       "      <th>question</th>\n",
       "      <th>Actual_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_Sichuan_earthquake</td>\n",
       "      <td>0.209195</td>\n",
       "      <td>311</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>347</td>\n",
       "      <td>0.100791</td>\n",
       "      <td>11</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_Summer_Olympics_torch_relay</td>\n",
       "      <td>3.655016</td>\n",
       "      <td>45</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>79</td>\n",
       "      <td>0.090815</td>\n",
       "      <td>22</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51st_state</td>\n",
       "      <td>5.702542</td>\n",
       "      <td>13</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.066697</td>\n",
       "      <td>382</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  bm25_score  bm25_rank  tfidf_score  \\\n",
       "0           2008_Sichuan_earthquake    0.209195        311     0.000451   \n",
       "1  2008_Summer_Olympics_torch_relay    3.655016         45     0.005532   \n",
       "2                        51st_state    5.702542         13     0.012178   \n",
       "\n",
       "   tfidf_rank  doc2vec_score  doc2vec_rank  \\\n",
       "0         347       0.100791            11   \n",
       "1          79       0.090815            22   \n",
       "2          41      -0.066697           382   \n",
       "\n",
       "                                            question  Actual_Document  \n",
       "0  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "1  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "2  To whom did the Virgin Mary allegedly appear i...                0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat(frames, ignore_index=True)\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv('Combined_Dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('Combined_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_rank</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>tfidf_rank</th>\n",
       "      <th>doc2vec_score</th>\n",
       "      <th>doc2vec_rank</th>\n",
       "      <th>question</th>\n",
       "      <th>Actual_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_Sichuan_earthquake</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>311</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>347</td>\n",
       "      <td>0.683617</td>\n",
       "      <td>11</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_Summer_Olympics_torch_relay</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>45</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>79</td>\n",
       "      <td>0.667423</td>\n",
       "      <td>22</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51st_state</td>\n",
       "      <td>0.075982</td>\n",
       "      <td>13</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>41</td>\n",
       "      <td>0.411718</td>\n",
       "      <td>382</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASCII</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>211</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>216</td>\n",
       "      <td>0.564947</td>\n",
       "      <td>150</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_cappella</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>181</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>277</td>\n",
       "      <td>0.485875</td>\n",
       "      <td>287</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  bm25_score  bm25_rank  tfidf_score  \\\n",
       "0           2008_Sichuan_earthquake    0.002787        311     0.000690   \n",
       "1  2008_Summer_Olympics_torch_relay    0.048700         45     0.008462   \n",
       "2                        51st_state    0.075982         13     0.018628   \n",
       "3                             ASCII    0.006013        211     0.002844   \n",
       "4                        A_cappella    0.013270        181     0.001741   \n",
       "\n",
       "   tfidf_rank  doc2vec_score  doc2vec_rank  \\\n",
       "0         347       0.683617            11   \n",
       "1          79       0.667423            22   \n",
       "2          41       0.411718           382   \n",
       "3         216       0.564947           150   \n",
       "4         277       0.485875           287   \n",
       "\n",
       "                                            question  Actual_Document  \n",
       "0  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "1  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "2  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "3  To whom did the Virgin Mary allegedly appear i...                0  \n",
       "4  To whom did the Virgin Mary allegedly appear i...                0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_combined_df = combined_df\n",
    "\n",
    "normalized_combined_df['bm25_score'] = (normalized_combined_df.bm25_score-min(normalized_combined_df.bm25_score))/(max(normalized_combined_df.bm25_score)-min(normalized_combined_df.bm25_score))\n",
    "normalized_combined_df['tfidf_score']=(normalized_combined_df.tfidf_score-min(normalized_combined_df.tfidf_score))/(max(normalized_combined_df.tfidf_score)-min(normalized_combined_df.tfidf_score))\n",
    "normalized_combined_df['doc2vec_score']=(normalized_combined_df.doc2vec_score-min(normalized_combined_df.doc2vec_score))/(max(normalized_combined_df.doc2vec_score)-min(normalized_combined_df.doc2vec_score))\n",
    "\n",
    "normalized_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>doc2vec_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.683617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.667423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075982</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.411718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.564947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.485875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bm25_score  tfidf_score  doc2vec_score\n",
       "0    0.002787     0.000690       0.683617\n",
       "1    0.048700     0.008462       0.667423\n",
       "2    0.075982     0.018628       0.411718\n",
       "3    0.006013     0.002844       0.564947\n",
       "4    0.013270     0.001741       0.485875"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = normalized_combined_df[['bm25_score','tfidf_score','doc2vec_score']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Document\n",
       "0                0\n",
       "1                0\n",
       "2                0\n",
       "3                0\n",
       "4                0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = normalized_combined_df[['Actual_Document']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LinearRegression()\n",
    "model3.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_doc(query,model):\n",
    "        BM_25_Dataframe = bm25(query).head(20)\n",
    "        TFDIF_Dataframe = tfidf(query).head(20)\n",
    "        Doc2Vec_Dataframe = doc2vec(query).head(20)\n",
    "        \n",
    "        final_doc_df = pd.merge(pd.merge(BM_25_Dataframe, TFDIF_Dataframe,on=['title'],how='outer'), Doc2Vec_Dataframe,on=['title'],how='outer')\n",
    "        final_doc_df = final_doc_df.fillna(0)\n",
    "        final_doc_df['bm25_score'] = (final_doc_df.bm25_score-final_doc_df.bm25_score.min())/(final_doc_df.bm25_score.max()-final_doc_df.bm25_score.min())\n",
    "        final_doc_df['tfidf_score'] = (final_doc_df.tfidf_score-final_doc_df.tfidf_score.min())/(final_doc_df.tfidf_score.max()-final_doc_df.tfidf_score.min())        \n",
    "        final_doc_df['doc2vec_score'] = (final_doc_df.doc2vec_score-final_doc_df.doc2vec_score.min())/(final_doc_df.doc2vec_score.max()-final_doc_df.doc2vec_score.min()) \n",
    "        final_doc_X = final_doc_df[['bm25_score','tfidf_score','doc2vec_score']]\n",
    "        \n",
    "        final_doc_df['total_score'] = model.predict(final_doc_X)\n",
    "        #final_doc_df['total_score'] = 0.01243557 * final_doc_df['bm25_score'] + 0.29682442 * final_doc_df['tfidf_score'] - 0.01673123 * final_doc_df['doc2vec_score']\n",
    "        return final_doc_df.sort_values(by='total_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Web_browser'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc('Who is Beyonce?',model2)['title'].head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    Tristan_da_Cunha\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_doc('Who is Beyonce?',model3)['title'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_context_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_index in range(len(data)):\n",
    "    context = ''\n",
    "    for context_index in range(len(data['passages'][row_index])):\n",
    "        context = context + data['passages'][row_index][context_index]['context']\n",
    "    title_context_dict[data['title'][row_index]]=context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd_distances(query,contexts):\n",
    "    list_distances = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sent1 = [word for word in nltk.word_tokenize(query) if word not in stop_words]\n",
    "    tag = nltk.pos_tag(sent1)\n",
    "    words = []\n",
    "    for each_tag in tag:\n",
    "        if each_tag[1] in ['NN','NNP','NNS','VBD','VB']:\n",
    "            words.append(each_tag[0])\n",
    "    sent1 = words        \n",
    "    \n",
    "    for cont in nltk.sent_tokenize(contexts):\n",
    "        sent2 = [word for word in nltk.word_tokenize(cont) if word not in stop_words]\n",
    "        wmd_distance = wmd_model.wmdistance(sent1,sent2)\n",
    "        list_distances.append(wmd_distance)\n",
    "        \n",
    "    WMD_Dataframe = pd.DataFrame({'Sentence': nltk.sent_tokenize(contexts), 'WMD_Score': list_distances}).sort_values(by=['WMD_Score'],ascending=True)\n",
    "    Top8_sentences = ' '.join([sent for sent in WMD_Dataframe[0:8].Sentence])\n",
    "    return Top8_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is Grotto at Notre Dame?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_context(query):\n",
    "    doc = final_doc(query,model2)['title'].head(1)[0]\n",
    "    print(\"DOC\",doc)\n",
    "    context = title_context_dict[doc]\n",
    "    wmd_distance = wmd_distances(query,context)\n",
    "    \n",
    "    return wmd_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Notre Dame\\'s most recent[when?] Kelly\\'s record in midway through his sixth season at Notre Dame is 52–21. Later that day, the trumpet section will play the Notre Dame Victory March and the Notre Dame Alma Mater under the dome. It was written by two brothers who were Notre Dame graduates. The Notre Dame Leprechaun is the mascot of the athletic teams. The 32 wins were the most by the Fighting Irish team since 1908-09.The \"Notre Dame Victory March\" is the fight song for the University of Notre Dame. Notre Dame moved its hockey team to Hockey East. What though the odds be great or small, old Notre Dame will win over all.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_context(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
